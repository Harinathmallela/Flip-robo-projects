{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\harinath\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\harinath\\anaconda3\\lib\\site-packages (from selenium) (1.25.9)\n"
     ]
    }
   ],
   "source": [
    "#Installing Selenium to perform WEb scraping.\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries to perform webscraping.\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import  NoSuchElementException\n",
    "import time"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chromedriver is a .exe file that your WebDriver interface uses to initiate the Google Chrome browser.\n",
    "driver = webdriver.Chrome('Chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver.get(url) is used to open an url and loads the whole page. so below code used to open naukari web page.\n",
    "url=\"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching the “Data Analyst” in “Skill,Designations,Companies” field and  “Bangalore” in “enter the location” field.\n",
    "#then clicking the search button using the respective tags\n",
    "\n",
    "search_bar=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_bar.clear()\n",
    "search_bar.send_keys('Data Analyst')\n",
    "search_bar1=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_bar1.clear()\n",
    "search_bar1.send_keys('Bangalore')\n",
    "time.sleep(10)\n",
    "search_button=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list for storing the data.\n",
    "name=[]\n",
    "location=[]\n",
    "company=[]\n",
    "experience=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the job details using for loop\n",
    "for i in range(1):\n",
    "    for j in driver.find_elements_by_xpath('//div[@class=\"info fleft\"]/a'):\n",
    "        name.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span'):\n",
    "        location.append(k.text)\n",
    "    for m in driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]'):\n",
    "        company.append(m.text)\n",
    "    for n in driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span'):\n",
    "        experience.append(n.text)\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "#Checking  the length of each list of job details.\n",
    "print(len(name),len(location),len(company),len(experience))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job title</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assistant Vice President - MIS &amp; Reporting ( B...</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...</td>\n",
       "      <td>12-18 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - Informatica MDM</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Kolkata, Pune, Chennai, Bangalore/Bengaluru, D...</td>\n",
       "      <td>SA Tech Software (I) Pvt. Ltd.</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For Data Analyst/ MIS Reporting Analyst...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt Ltd</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data analyst - Google Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>H and M Hennes and Mauritz (P) Ltd.</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior/Regular Business Analyst / Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Luxoft</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For Data Analyst @ Flipkart on Contract</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1  Assistant Vice President - MIS & Reporting ( B...   \n",
       "2                     Data Analyst - Informatica MDM   \n",
       "3                                       Data Analyst   \n",
       "4                                       Data Analyst   \n",
       "5  Hiring For Data Analyst/ MIS Reporting Analyst...   \n",
       "6                    Data analyst - Google Analytics   \n",
       "7     Senior/Regular Business Analyst / Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9     Hiring For Data Analyst @ Flipkart on Contract   \n",
       "\n",
       "                                        Job-location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1                        Mumbai, Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4  Kolkata, Pune, Chennai, Bangalore/Bengaluru, D...   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                        company_name experience_required  \n",
       "0                 Inflexion Analytix Private Limited             0-3 Yrs  \n",
       "1  INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...           12-18 Yrs  \n",
       "2                Shell India Markets Private Limited             6-9 Yrs  \n",
       "3                           Myntra Designs Pvt. Ltd.             3-6 Yrs  \n",
       "4                     SA Tech Software (I) Pvt. Ltd.             1-3 Yrs  \n",
       "5   PHARMACEUTICAL RESEARCH ASSOCIATES INDIA Pvt Ltd             2-4 Yrs  \n",
       "6                H and M Hennes and Mauritz (P) Ltd.             4-7 Yrs  \n",
       "7                                             Luxoft             3-6 Yrs  \n",
       "8                  Flipkart Internet Private Limited             1-3 Yrs  \n",
       "9                  Flipkart Internet Private Limited             2-6 Yrs  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the DataFrame using pandas \n",
    "job={\"Job title\":name[:10],\" Job-location\":location[:10],\"company_name\":company[:10],'experience_required':experience[:10]}\n",
    "df=pd.DataFrame(job)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the dataframe as csv file.\n",
    "df.to_csv('1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- 1. All of the above steps have to be done in code. No step is to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chromedriver is a .exe file that your WebDriver interface uses to initiate the Google Chrome browser.\n",
    "driver = webdriver.Chrome('Chromedriver.exe')\n",
    "#driver.get(url) is used to open an url and loads the whole page. so below code used to open naukari web page.\n",
    "url=\"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching the “Data Scientist” in “Skill,Designations,Companies” field and  “Bangalore” in “enter the location” field.\n",
    "#then clicking the search button using the respective tags\n",
    "search_bar=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_bar.clear()\n",
    "search_bar.send_keys('Data Scientist')\n",
    "search_bar1=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_bar1.clear()\n",
    "search_bar1.send_keys('Bangalore')\n",
    "time.sleep(10)\n",
    "search_button=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list for storing the data\n",
    "name=[]\n",
    "location=[]\n",
    "company=[]\n",
    "job_desc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching for each job using their respective urls to scrap the required details.\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the job name,location,company using their respective tags. \n",
    "for i in range(1):\n",
    "    for j in driver.find_elements_by_xpath('//div[@class=\"info fleft\"]/a'):\n",
    "        name.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span'):\n",
    "        location.append(k.text)\n",
    "    for m in driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]'):\n",
    "        company.append(m.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(name),len(location),len(company))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Job description\\nJob Role : Data Scientist/Data Analyst /Business Analyst\\n\\nLocation : Chennai/Bangalore/Hyderabad/Pune/Mumbai/Delhi\\n\\nGreetings from CAIA - Center for Artificial Intelligence & Advanced Analytics\\n43% of companies experienced a high deficit of skilled resources with Advanced Analytical skills and AI implementing capabilities in year 2020. CAIA gives you a great opportunity to enter the world of future technologies and Innovations- Data Science, Analytics, AI, Data Visualization and Cloud Computing.\\n\\nWhile 2020 was a year like no other, we are living in an interesting times where data is reshaping the world, and businesses are rapidly adopting technology to gain an edge over others. Hence, there's a substantial increase in demand for technology professionals who can implement systems in data science, machine learning and AI in Tier 1 and Tier 2 organization's working closely with us.\\n\\nTo help you build a sustainable career we would like you to utilize data, software and Analytical approaches in Data Science and AI to up skill and get recruited into an organization appreciating your skilling journey.\\nApplications invited from all Freshers and experienced candidates (0-3 yrs) aspiring to make a career in Artificial Intelligence and Advanced Analytics and Data Science.\\nIf you wish to make a shift in your career or undergo a career transition, upskilling is essential since it allows you to learn more about the domain and acquire the required skills.\\n\\nCall to schedule interview Monday -Saturday from 10:00 am to 7Pm\\n\\nManigandan -+91 7299917200\\n\\nEmail : manigandan@centerforaia.com\\n\\nWhat is needed from you?\\n\\nFreshers who wish to start their career in Analytics and AI and professionals who wish to\\nupskill or change their domain to analytics and emerging technologies are free to apply.\\nAn Educational background in any one of the following- BE/B.Tech, ME/M Tech, MSc, BSc/MSc Maths and Statistics, B Com, BCA, BSc CS, BSC IT, MSC IT, MCA\\nSkills relating to Mathematics/Statistics.\\nNatural passion towards numbers, business, coding, Analytics and Artificial Intelligence, Machine Learning, visualization\\nGood verbal and written communication skills\\nAbility to understand domains in businesses across various sectors\\n\\n\\nSelection procedure includes\\n\\nAptitude Test & Communication Exam - Online / Offline\\nSQL/Python test - Online / Offline\\n\\nCandidates who clears the above will have one-one discussion with our Career Guidance Manager for further evaluation and processing of your Resume.\\n\\n\\nAll the Shortlisted candidates will be eligible to continue the corporate training with CAIA\\nWhat you can expect from us?\\n\\nYou will get trained on the following modules for a period of 12-14 weeks:\\n\\nSQL & PLSQL\\nData Wrangling using Python\\nData Visualization Using Power-BI\\nStatistics for Machine Learning\\nArtificial Intelligence, Data Interpretation\\nSupervised & Unsupervised Learning,\\nNLP & Deep Learning\\nCloud Data Lake\\nBusiness intelligence & Data Visualization\\nSimulation Projects\\nExpected Outcome?\\n\\nAt the end of the Training you are expected to be well versed with the following:\\n\\nAnalysis of large and complex data sets from multiple sources\\nDevelopment and evaluation of data analytics models, algorithms and solutions\\nUnderstanding/implementation of ML algorithms, performance tuning and reporting\\nImplementation of algorithms to mine targeted data and the ability to convert data in to a business story\\nTranslation of business requirements into technical requirements; Data extraction, preparation and transformation\\nIdentification, development and implementation of statistical techniques and algorithms that address business challenges and adds value to the organization\\nRequirement Analysis and communication of findings in the form of a meaningful story with the stakeholders\\nFinding analytical solutions to abstract business issues.\\nApply objective analysis of facts before coming to a conclusion\\n\\nAbout CAIA - Inflexion Analytix Private Limited\\n\\nCenter for Artificial Intelligence and Advanced Analytics (Center for AIA) is the brainchild of experienced and visionary alumni of IIT Madras and Bombay.\\nDigital leaders - 5F World and Systech Solutions have joined hands to create a venture for architecting the future of society, workforce, governments and businesses. 5F World specializes in designing solutions around digital platforms and Systech Solutions has an expertise in architecting Artificial Intelligence and Advance Analytics solutions for Fortune 500 companies.\\nOur Website : http://www.centerforaia.com/\\n\\nhttps://inflexion-analytix-private-limited.business.site/?m=true\\n\\nCenter for Artificial Intelligence & Advanced Analytics (CAIA) focuses on the following:\\n\\n1. Global Research on emerging trends, technologies and applications in AI and Advanced Analytics\\n2. Advanced Training programs for readying the future ready workforce\\n3. Solutions to herald the futuristic lifestyle and workspaces in the field of AI and Data Science.\\nRoleData Analyst\\nIndustry TypeBPO / Call Centre\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate in Any Specialization\\nKey Skills\\nBusiness IntelligenceArtificial IntelligenceBig DataITMachine LearningStatisticsDeep LearningAnalyticsBusiness AnalysisSQLData ScienceNLPCloud ComputingData VisualizationSoftwareData WarehousingPython\",\n",
       " 'Job description\\nWe wont say we can predict the future, but our team of Analysts get pretty close, they turn millions of data points into useful information & insights that help our clients to make better decisions on their marketing mix and achieve superior results. Be part of the future and join in on one of the major transformations in the market research industry with the integration of big data and classic marketing mix analysis.\\n\\nResponsibilities:\\nDeliver as a part of our consultant team in driving high quality results on custom project work\\nEnsure effective and timely delivery of project work\\nWork towards understanding statistical models and deliver business insights and findings\\nEnsure compliance to Marketing Mix Modeling modeling practices and company quality standards\\nMaximize the efficient and effective use of resources by utilizing appropriate processes and tools\\nTo build and maintain effective contacts with other departments to ensure the efficient and effective use of resources\\nLiaise with appropriate Marketing Mix Modeling and Nielsen departments to ensure hardware and software requirements are fulfilled\\nWork with co/ third party modellers to deliver business insights and findings\\n\\nQualifications and Skills\\n2-5 years of relevant experience\\nMasters degree in Economics, Mathematics, Statistics, Engineering\\nIn-depth understanding of statistical modeling techniques and applications\\nGood and working knowledge of any statistical languages like SAS, R, Pythons\\nSolid proficiency of decision making and problem resolution skills\\nPassion for results with a challenger mindset\\n\\nAbout the Team:\\nGlobal Product, Technology & Operations supports Nielsen Medias growth strategy by enabling positive client and market solutions. Our Operations Team is in a unique position as the center of data collection, analysis and delivery. We deliver outcomes with the highest quality and integrity standards in an agile and transparent way while standing by our Nielsen values.\\n\\n\\nRoleBusiness Analyst\\nIndustry TypeAnalytics / KPO / Research\\nFunctional AreaStrategy, Management Consulting, Corporate Planning\\nEmployment TypeFull Time, Permanent\\nRole CategoryCorporate Planning/Consulting/Strategy\\nEducation\\nPG :MBA/PGDM in Any Specialization, M.A in Economics, MS/M.Sc(Science) in Statistics, Maths\\nKey Skills\\nPredictive ModelingSASSegmentationK-MeansStatisticsOptimizationRandom ForestRMarketing Mix ModelingLinear RegressionStatistical ModelingBusiness InsightsMarket Research',\n",
       " 'Not Available',\n",
       " 'Job description\\nResponsibilities and Key Result Areas\\nDesign and develop project prototypes and solutions.\\nParticipate in project estimation, planning and risk management activities\\nIs responsible for delivering input in the planning process to the project leader\\nEnsures that there is proper documentation for the developed solutions.\\nEnsure compliance to the Quality Management System and regulatory requirements\\nKey Technical Skills:\\n4 - 7 yrs years of experience in data science\\nDeveloped Proficient in algorithms on regression modelling (linear/logistic), supervised and unsupervised classification,\\ntree-based techniques (Decision trees /Random forest), neural nets, bagging, Pattern Mining and boosting techniques, etc.\\nProficient and hands on experience in developing models using concepts of Artificial Intelligence,\\nMachine Learning and Deep Learning related technologies (such as Keras, TensorFlow, pyTorch, Azure ML, AWS ML, Scikit, Jupyter, MatLab etc.)\\nExperience with containers like Docker is added advantage\\nExperience in Sql\\nWorking experience in agile/SAFe development methodologies\\nSoft Skill set:\\nFast learner. Ability to grasp key concepts quickly with minimal or no supervision\\nGo-Getter Attitude. Ability to take ownership of team goals and deliver it with quality and within required timeline\\nTeam Player attitude. Key characteristic of the individual who puts the team first before self.\\nAbility to think out of box: Ability to come up with bright ideas and always looking at the next big thing in technology\\nFlexible and willingness to stretch oneself when needed.\\nRoleSoftware Developer\\nIndustry TypeMedical Services / Hospital\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate in Any Specialization\\nPG :Post Graduation Not Required\\nKey Skills\\nMiningdeep learningdata scienceArtificial IntelligenceMachine learningAgileHTMLRisk managementMATLABSQL',\n",
       " 'Not Available',\n",
       " 'Job description\\n\\n\\nWe are seeking an outstanding Lead Data Scientist in AI/ML who will help our team continue to grow and bring high value to Intel. In this role you should demonstrate excellent problem formulation/definition skills in addition to technical skills. The ideal candidate should be:\\n\\nA professional role model with deep and wide expertise in state-of-the-art AI/ML techniques, a passion for solving challenging data science problems and extensive hands-on experience.\\nBe detail-oriented and have an aptitude for solving unstructured problems. You should be excellent in coming up with different approaches to solve business problem using AI and evaluate the trade-off between them.\\nBe self-directed, take charge of opportunities with business impact and drive them to completion.\\nHave prior experience in guiding a team of data scientists, coaching and mentoring them.\\nHave deep technical expertise in feature-engineering of massive datasets, effective exploratory data analysis, and model building using AI/ML techniques.\\nBe a role model innovator by adapting new AI/ML modeling techniques and procedures.\\nHave deep expertise in creation and management of datasets.\\nHave excellent business and communication skills to be able to work with stakeholders like the business teams, engineering teams and partner teams and align them with respect to your focus area.\\nHave the ability to manage and execute an entire AI project from start to finish, including problem solving, data gathering and manipulation, predictive modeling, and project management skills.\\nBe a role-model in storytelling with data and articulating the AI problems in an understandable manner to senior leadership of the Business Units.\\n\\nYou will be a part of the large global AI/ML Research Scientist community and will have access to state-of-the-art training, tools, and methods of the domain.\\n\\n\\nCandidates need to hold at least a masters degree (or higher) in Computer Science/Machine Learning/AI/Data Science\\n8 years of relevant experience in building AI/ML models and in using Python (Scikit-learn, TensorFlow/Pytorch) and SQL (or equivalent).\\nExperience in using data analysis techniques and ML methods like classification, regression pattern finding, clustering, dimensionality reduction, anomaly detection etc.\\nExperience with Hadoop, Spark is an advantage\\nDeep Knowledge of classical AI algorithms and Deep Learning techniques is a must.\\nGreat analytical skills and demonstrated ability of independent and creative thinking.\\nHighly motivated strong team player with the ability to work both independently and collaboratively within a team.\\nHas strong analytical skills, including the abilities to scope out business problems to be solved, start from ambiguous problem statements, identify and access relevant data, make appropriate assumptions, perform insightful analysis and draw conclusions relevant to the business problem.\\nAbility to present information professionally and concisely with supporting data.\\nPrevious experience as a data scientist in semi-conductor industry or data intensive organizations is a plus.\\nExperience in creating powerful data driven visualizations to describe ML modeling results to stakeholders.\\nRoleTeam Lead/Technical Lead\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryProgramming & Design\\nEducation\\nUG :Any Graduate in Any Specialization\\nPG :Any Postgraduate in Any Specialization\\nKey Skills\\nComputer scienceData analysisFormulationArtificial IntelligenceMachine learningSignal processingPredictive modelingForecastingSQLPython',\n",
       " 'Not Available',\n",
       " 'Job description\\nBusiness & Team overview:\\nFounded in 1987, Huawei is a leading global provider of ICT (information and communications technology) infrastructure and smart devices. We are committed to bringing digital to every person, home and organization for a fully connected, intelligent world. We have nearly 194,000 employees, and we operate in more than 170 countries and regions, serving more than 3 billion people around the world.\\n\\nHuawei Technologies has three business directions: Carrier Business Group, which provides innovative and secure network equipment to telecom carriers, including the leading 5G mobile network.\\nEnterprise Business Group, which provides facilities and solutions to big and small companies, including IT facilities.\\nConsumer Business Groups, which provides devices to the customer, including mobile phones, PC, tablet, TV, audio, glasses, watches, locomotives, and headphones. And also provide solutions on mobile offices, smart homes, sports and health, audio-visual entertainment, and smart travel products.\\n\\nThis opportunity is belong to Huawei Consumer Business Group.\\n\\nDriven by the coordinated development of \"Chip-Device-Cloud\", consumer products such as smartphones are becoming increasingly intelligent and pervasive. The era of smart services is the future.\\n\\nHuawei Ads Services is dedicated to provide Huawei end-users with high-quality digital experiences, to build a business closed-loop system for Developers and Improve the ROI for the Advertisers\\n.\\nIn 2020 Q1, along with more than 650 million users and 1,400,000 registered developers worldwide, we have the following unique advantages:\\n1. With All-scenario intelligent solution, the Huawei devices become super entrance of traffic, including mobile phones, PC, tablet, TV, audio, glasses, watches, locomotives, and head phones\\n2. This team will be responsible for building a new Ad Serving Platform and have the opportunity to define the product for our Huawei end-users.\\n3. AI-Driven is the direction of Ads, Huawei is going to build a strong team in India to Innovate and deliver AI-driven Smart Ad Serving Platforms\\n\\nJob Title: Lead Data Scientist\\nWe are looking for a Lead data scientist who will help us discover the information hidden in vast amounts of Ad Campaign data, and help us to optimize the campaign to improve the advertiser ROI and improve the overall consumer experience. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems using Deep learning algorithms integrated with our products. Some the key area you will be working on spend recommendation, floor price prediction, CTR/CVR prediction, market funnel analysis and perdition of lead to conversion, etc.\\n\\nResponsibility:\\nAnalyze the data, develop insights and identify the opportunity to utilize the data to predict various Advertisement key indicators like CTR, CVR, Inventory and Develop prediction and optimization algorithms for campaign, look alike modeling, etc for Huawei Ads.\\nTakeup key challenges in AI-driven Smart Ad Serving Platform and focus on research and developing leading AI algorithms and productionize for Huawei Ads.\\nTakeup initiative in identifying the SOTA and finding key gaps in AI algorithms and develop a world leading AI algorithms for optimizing real-time Ad Serving engine. Identify and optimize the core modules such as Traffic Prediction, Optimization, Ad Targeting/Re-targeting, Ad Performance Optimization, Audience insights, Attribution, Bidding, re-ranking, and Diagnostics. Support hundreds of billions of ad requests per day, with efficiently cache technology.\\nTo build and enhance Ad platform features and Prediction capabilities in Huawei Ads Platform\\nOptimized Cost Per Mille; Optimized Cost Per Action; Optimized Cost Per Click and Cost per Click. OCPM, OCPA, OCPC.\\n\\nRequirements:\\n- Strong hands-on experience in implementing and validating big data algorithms and models including Deep Learning models like Seq2Seq/ GRU/RNN/LSTM , Knowledge Graph, Massive Graph algorithms, etc.\\n- Programming experience with Python\\n- Able to validate existing models including Deep Learning models with large scale dataset and able to make changes to the models to achieve better performance\\n- AdServing domain Experience is an added advantage\\nRoleAnalytics Manager\\nIndustry TypeTelecom / ISP\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate in Any Specialization\\nPG :Any Postgraduate in Any Specialization\\nKey Skills\\nRnnAlgorithmsLstmArtificial IntelligenceData ScientistBig DataData MiningStatistical AnalysisDeep LearningPython',\n",
       " 'Job description\\nBusiness & Team overview:\\nFounded in 1987, Huawei is a leading global provider of ICT (information and communications technology) infrastructure and smart devices. We are committed to bringing digital to every person, home and organization for a fully connected, intelligent world. We have nearly 194,000 employees, and we operate in more than 170 countries and regions, serving more than 3 billion people around the world.\\n\\nHuawei Technologies has three business directions: Carrier Business Group, which provides innovative and secure network equipment to telecom carriers, including the leading 5G mobile network.\\nEnterprise Business Group, which provides facilities and solutions to big and small companies, including IT facilities.\\nConsumer Business Groups, which provides devices to the customer, including mobile phones, PC, tablet, TV, audio, glasses, watches, locomotives, and headphones. And also provide solutions on mobile offices, smart homes, sports and health, audio-visual entertainment, and smart travel products.\\n\\nThis opportunity is belong to Huawei Consumer Business Group.\\n\\nDriven by the coordinated development of \"Chip-Device-Cloud\", consumer products such as smartphones are becoming increasingly intelligent and pervasive. The era of smart services is the future.\\nHuawei Ads Services is dedicated to provide Huawei end-users with high-quality digital experiences, to build a business closed-loop system for Developers and Improve the ROI for the Advertisers\\n.\\nIn 2020 Q1, along with more than 650 million users and 1,400,000 registered developers worldwide, we have the following unique advantages:\\n1. With All-scenario intelligent solution, the Huawei devices become super entrance of traffic, including mobile phones, PC, tablet, TV, audio, glasses, watches, locomotives, and head phones\\n2. This team will be responsible for building a new Ad Serving Platform and have the opportunity to define the product for our Huawei end-users.\\n3. AI-Driven is the direction of Ads, Huawei is going to build a strong team in India to Innovate and deliver AI-driven Smart Ad Serving Platforms\\n\\n1. Job Title: Computational Design Lead Data Scientist\\n\\nResponsibility:\\nTake-up Key creative tools of the creative platform for Advertisers, research and develop breakthrough CNN based deep learning algorithms to solve the problem unique in the industry and productionize the algorithms, measure the ad creative performance and enhance the algorithm to ease the Ad Designer job.\\nDevelop the common AI platforms and frameworks to ease the experimentation of the Algorithms for creative Design.\\nTo build ability to understand the advertisers intent and provide creative assistance every step of creating all types of adverts\\nResponsible for intelligent identification of advertising creatives (pictures, videos) and related algorithms of content understanding.\\nResponsible for Image Synthesis, Intelligent Layout, Style Transfer, and other image processing, computing and visual processing, to improve the aesthetic level of advertising creativity.\\nResponsible for designing algorithms for suggesting how to intelligently crop and position an image for maximum effect, identify the optimal placement of text and copywriting.\\nResponsible for the algorithm and model of dynamic matching of advertising program creativity and dynamic creation of advertising content\\n\\nRequirements:\\nDeep knowledge of Computational Design\\nExperience on Intelligent composition, including image cropping, smart layout, the Gold Ratio composition, visual extension.\\nExperience computer vision models, including image/video recognition and content understanding.\\nExperience in algorithms such as image and video segmentation, separation, synthesis, and intelligent layout with engineering platform implementation capability.\\nStrong Knowledge Algorithms such as Image segmentation, object detection, Image processing (filtering, noise removal, histogram thresholding, etc.), object tracking, image transformation (affine transform, dewarping), keypoint detection/description, etc (and experience in using Computer vision Libraries)\\nStrong Knowledge in CNN, R-CNN, GAN, LSTM, GRU, Multimodal feature Learning, ASR, NLU, NLG, Copywriting and KG will be an added advantage\\nStrong logic/probability thinking ability and be good at analyzing, summarizing, describing, communicating, and solving problems\\nWorking experience in related online advertising products/creative platform is preferred\\nWorking experience in Computer Vision (CV) to enhance user artistic creativity while creating creatives/adverts is preferred\\nAbility to identify trends of advertising creative platform.\\n\\n\\nRoleData Analyst\\nIndustry TypeTelecom / ISP\\nFunctional AreaAnalytics & Business Intelligence\\nEmployment TypeFull Time, Permanent\\nRole CategoryAnalytics & BI\\nEducation\\nUG :Any Graduate in Any Specialization\\nPG :Any Postgraduate in Any Specialization\\nKey Skills\\nObject DetectionR-CNNCnnAlgorithmsLstmGANArtificial IntelligenceImage ProcessingData ScientistComputer VisionComputational DesignDeep Learning',\n",
       " 'Job description\\nDear Aspirant,\\n\\nGreetings from Globaledx\\n\\nRoles and Responsibilities\\n\\nExperience : 3+ Years\\nCTC : Best in Market\\nLocation : Pan India\\nContract Period : 3-6 Months\\nSkill : Python, NLP, Machine Learning Models, Data Scientist\\n\\nInterested, please share your updated resume to hr@globaledx.com\\nOr Call /Whatsapp at Sowjanya : 9505072408\\n\\nPlease share with your friends for more reach!\\nRoleIT/Technical Content Developer\\nIndustry TypeIT Services & Consulting\\nFunctional AreaIT Software - Application Programming, Maintenance\\nEmployment TypeFull Time, Permanent\\nRole CategoryOther\\nEducation\\nUG :Any Graduate in Any Specialization\\nKey Skills\\nPostgresqlDATA SCIENTISTMachine LearningScikit-LearnsqlpandasNLPoptimal codingRundeckmachine learning modelslogging frameworkshtmlNUMPYPython']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping the job description. \n",
    "for url in urls[0:10]:\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        description=driver.find_element_by_xpath(\"//section[@class='job-desc']\").text\n",
    "        job_desc.append(description)\n",
    "    except NoSuchElementException :\n",
    "        job_desc.append(\"Not Available\")\n",
    "job_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job title</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>Job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Job description\\nJob Role : Data Scientist/Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist, Modeling</td>\n",
       "      <td>Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...</td>\n",
       "      <td>Nielsen</td>\n",
       "      <td>Job description\\nWe wont say we can predict th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big Data - Data Scientist</td>\n",
       "      <td>Kochi/Cochin, Indore, Hyderabad/Secunderabad, ...</td>\n",
       "      <td>Xoriant Solutions Pvt Ltd</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Specialist I - Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Job description\\nResponsibilities and Key Resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Intel Technology India Pvt Ltd</td>\n",
       "      <td>Job description\\n\\n\\nWe are seeking an outstan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Oracle India Pvt. Ltd.</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SDE Lead Data Scientist-L3</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Huawei Technologies India Pvt Ltd</td>\n",
       "      <td>Job description\\nBusiness &amp; Team overview:\\nFo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Computational Design Lead Data Scientist-L3</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Huawei Technologies India Pvt Ltd</td>\n",
       "      <td>Job description\\nBusiness &amp; Team overview:\\nFo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For DATA Scientist - ON Contract Basis ...</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, M...</td>\n",
       "      <td>GlobalEdx Learning and Technology Solution Pvt...</td>\n",
       "      <td>Job description\\nDear Aspirant,\\n\\nGreetings f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                    Senior Data Scientist, Modeling   \n",
       "2                          Big Data - Data Scientist   \n",
       "3                      Specialist I - Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5                                Lead Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                         SDE Lead Data Scientist-L3   \n",
       "8        Computational Design Lead Data Scientist-L3   \n",
       "9  Hiring For DATA Scientist - ON Contract Basis ...   \n",
       "\n",
       "                                        Job-location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1  Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...   \n",
       "2  Kochi/Cochin, Indore, Hyderabad/Secunderabad, ...   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9  Hyderabad/Secunderabad, Bangalore/Bengaluru, M...   \n",
       "\n",
       "                                        company_name  \\\n",
       "0                 Inflexion Analytix Private Limited   \n",
       "1                                            Nielsen   \n",
       "2                          Xoriant Solutions Pvt Ltd   \n",
       "3                              Philips India Limited   \n",
       "4                             IBM India Pvt. Limited   \n",
       "5                     Intel Technology India Pvt Ltd   \n",
       "6                             Oracle India Pvt. Ltd.   \n",
       "7                  Huawei Technologies India Pvt Ltd   \n",
       "8                  Huawei Technologies India Pvt Ltd   \n",
       "9  GlobalEdx Learning and Technology Solution Pvt...   \n",
       "\n",
       "                                     Job_description  \n",
       "0  Job description\\nJob Role : Data Scientist/Dat...  \n",
       "1  Job description\\nWe wont say we can predict th...  \n",
       "2                                      Not Available  \n",
       "3  Job description\\nResponsibilities and Key Resu...  \n",
       "4                                      Not Available  \n",
       "5  Job description\\n\\n\\nWe are seeking an outstan...  \n",
       "6                                      Not Available  \n",
       "7  Job description\\nBusiness & Team overview:\\nFo...  \n",
       "8  Job description\\nBusiness & Team overview:\\nFo...  \n",
       "9  Job description\\nDear Aspirant,\\n\\nGreetings f...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the DataFrame using pandas\n",
    "job={\"Job title\":name[:10],\" Job-location\":location[:10],\"company_name\":company[:10],'Job_description':job_desc[:10]}\n",
    "time.sleep(10)\n",
    "df=pd.DataFrame(job)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the dataframe as csv file.\n",
    "df.to_csv('2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chromedriver is a .exe file that your WebDriver interface uses to initiate the Google Chrome browser.\n",
    "driver = webdriver.Chrome('Chromedriver.exe')\n",
    "#driver.get(url) is used to open an url and loads the whole page. so below code used to open naukari web page.\n",
    "url=\"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the details in the search column and searching.\n",
    "search_bar=driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_bar.clear()\n",
    "search_bar.send_keys('Data Scientist')\n",
    "time.sleep(10)\n",
    "search_button=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_button.click()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying filter for job location\n",
    "checkbox=driver.find_element_by_xpath(\".//*[text()='Delhi / NCR']\")\n",
    "checkbox.click()\n",
    "time.sleep(10)\n",
    "# Let's create filter for salary\n",
    "checkbox1=driver.find_element_by_xpath(\".//*[text()='3-6 Lakhs']\")\n",
    "checkbox1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list for storing the data\n",
    "name=[]\n",
    "location=[]\n",
    "company=[]\n",
    "experience=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the job details using for loop\n",
    "for i in range(1):\n",
    "    for j in driver.find_elements_by_xpath('//div[@class=\"info fleft\"]/a'):\n",
    "        name.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span'):\n",
    "        location.append(k.text)\n",
    "    for m in driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]'):\n",
    "        company.append(m.text)\n",
    "    for n in driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span'):\n",
    "        experience.append(n.text)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(name),len(location),len(company),len(experience))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job title</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business Analyst- Data Scientist</td>\n",
       "      <td>Noida, Gurgaon/Gurugram</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - High growth VC backed Influen...</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>Ravgins International Pvt. Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Mobikwik</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Noida</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Blitz Jobs</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengal...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                   Business Analyst- Data Scientist   \n",
       "2  Data Scientist - High growth VC backed Influen...   \n",
       "3                                     Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5           DATA Scientist – Gurgaon (Exp 3-6 years)   \n",
       "6           DATA Scientist – Gurgaon (Exp 3-6 years)   \n",
       "7                             Data Scientist - Noida   \n",
       "8                                     Data Scientist   \n",
       "9         Data Scientist - Python & Machine Learning   \n",
       "\n",
       "                                        Job-location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1                            Noida, Gurgaon/Gurugram   \n",
       "2  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "3  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "4           New Delhi, Gurgaon/Gurugram, Delhi / NCR   \n",
       "5                      Gurgaon/Gurugram, Delhi / NCR   \n",
       "6                      Gurgaon/Gurugram, Delhi / NCR   \n",
       "7                                              Noida   \n",
       "8                                              Noida   \n",
       "9  Hyderabad/Secunderabad, Pune, Bangalore/Bengal...   \n",
       "\n",
       "                                        company_name experience_required  \n",
       "0                 Inflexion Analytix Private Limited             0-3 Yrs  \n",
       "1                                              Wipro             2-5 Yrs  \n",
       "2                    Ravgins International Pvt. Ltd.             3-5 Yrs  \n",
       "3                             IBM India Pvt. Limited             4-9 Yrs  \n",
       "4                                           Mobikwik             3-5 Yrs  \n",
       "5  CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...             3-6 Yrs  \n",
       "6  CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...             3-6 Yrs  \n",
       "7     Optum Global Solutions (India) Private Limited             3-5 Yrs  \n",
       "8                                         Blitz Jobs             3-5 Yrs  \n",
       "9                                FUTURES AND CAREERS             2-7 Yrs  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job={\"Job title\":name[:10],\" Job-location\":location[:10],\"company_name\":company[:10],'experience_required':experience[:10]}\n",
    "time.sleep(5)\n",
    "df=pd.DataFrame(job)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('3.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using Selenium scraped the job-title, job-location, company_name, experience_required  for  first 10 jobs data of  “Data Scientist ” Job position by applying “Delhi/NCR” and \"3-6 lakhs\" filters and stored as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field.\n",
    "3. Then click the search button. You will land up in the below page:\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown page.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chromedriver is a .exe file that your WebDriver interface uses to initiate the Google Chrome browser.\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "#driver.get(url) is used to open an url and loads the whole page. so below code used to open glass door web page.\n",
    "driver.get('https://www.glassdoor.co.in/index.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the login details \n",
    "driver.maximize_window()\n",
    "driver.find_element_by_xpath('//button[@class=\"d-none d-lg-block p-0 LockedHomeHeaderStyles__signInButton\"]').click()\n",
    "time.sleep(10)\n",
    "driver.find_element_by_xpath('//input[@id=\"userEmail\"]').send_keys('harinathmallela7@gmail.com')\n",
    "driver.find_element_by_xpath('//input[@id=\"userPassword\"]').send_keys('glassdoor123')\n",
    "time.sleep(5)\n",
    "driver.find_element_by_xpath('//button[@class=\"gd-ui-button minWidthBtn css-8i7bc2\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the details in the search column and searching.\n",
    "search_bar=driver.find_element_by_id('sc.keyword')\n",
    "search_bar.clear()\n",
    "search_bar.send_keys('Data Scientist')\n",
    "search_bar1=driver.find_element_by_id('sc.location')\n",
    "search_bar1.clear()\n",
    "time.sleep(5)\n",
    "search_bar1.send_keys('Noida')\n",
    "time.sleep(10)\n",
    "search_button=driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of urls per respective job. \n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath('//a[@class=\"jobLink css-1rd3saf eigr9kq2\"]'):\n",
    "    urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an empty list to store details\n",
    "job_title=[]\n",
    "company_name=[]\n",
    "rating=[]\n",
    "days=[]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the webpage using tags to get job details\n",
    "for i in range(1):\n",
    "    for j in driver.find_elements_by_xpath('//a[@class=\"jobLink css-1rd3saf eigr9kq2\"]/span'):\n",
    "        job_title.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath('//a[@class=\" css-l2wjgv e1n63ojh0 jobLink\"]/span'):\n",
    "        company_name.append(k.text) \n",
    "    for m in driver.find_elements_by_xpath('//div[@data-test=\"job-age\"]'):\n",
    "        days.append(m.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls[0:10]:\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        Rating=driver.find_element_by_xpath(\"//span[@class='css-1pmc6te e11nt52q4']\").text.replace('\\n','').replace('★','')\n",
    "        rating.append(Rating)\n",
    "    except NoSuchElementException :\n",
    "        rating.append(\"Not Available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job title</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>rating</th>\n",
       "      <th>days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Amplify Analytix</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>1d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist II</td>\n",
       "      <td>Kroll</td>\n",
       "      <td>3.7</td>\n",
       "      <td>9d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>H&amp;M</td>\n",
       "      <td>3.7</td>\n",
       "      <td>24h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Wise Monk</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>7d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Analyst- Data Science</td>\n",
       "      <td>Infosys Limited</td>\n",
       "      <td>3.8</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td>3.4</td>\n",
       "      <td>3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Applied Materials Inc.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analytics Internship</td>\n",
       "      <td>MyPaisaa</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>IBM</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Job title            Company_name         rating  \\\n",
       "0                      Data Scientist        Amplify Analytix  Not Available   \n",
       "1                   Data Scientist II                   Kroll            3.7   \n",
       "2                      Data Scientist                     H&M            3.7   \n",
       "3                      Data Scientist               Wise Monk  Not Available   \n",
       "4          Lead Analyst- Data Science         Infosys Limited            3.8   \n",
       "5                      Data Scientist                                    3.4   \n",
       "6                      Data Scientist  Applied Materials Inc.            4.0   \n",
       "7                Staff Data Scientist        General Electric            4.0   \n",
       "8           Data Analytics Internship                MyPaisaa            5.0   \n",
       "9  Data Scientist: Advanced Analytics                     IBM            3.9   \n",
       "\n",
       "   days  \n",
       "0    1d  \n",
       "1    9d  \n",
       "2   24h  \n",
       "3    7d  \n",
       "4  30d+  \n",
       "5    3d  \n",
       "6  30d+  \n",
       "7    1d  \n",
       "8    5d  \n",
       "9    1d  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job={\"Job title\":job_title[:10],\" Company_name\":company_name[:10],\"rating\":rating[:10],\"days\":days[:10]}\n",
    "df=pd.DataFrame(job)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Selenium scraped the job-title, company_name, ratings and days ago posted  for  first 10 jobs data of  “Data Scientist ” Job position in NOIDA location in glassdoor stored as a csv file.\n",
    "df.to_csv('4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company.\n",
    "6.Store the data in a dataframe.\n",
    "Note that all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using chromedriver and driver.get to open and load a chrome page.\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.glassdoor.co.in/Salaries/index.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maximizing the window\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the search_bar using tags and entering details to search \n",
    "search_bar=driver.find_element_by_id('KeywordSearch')\n",
    "search_bar.clear()\n",
    "search_bar.send_keys('Data Scientist')\n",
    "search_bar1=driver.find_element_by_id('LocationSearch')\n",
    "time.sleep(5)\n",
    "search_bar1.clear()\n",
    "search_bar1.send_keys('Noida')\n",
    "time.sleep(30)\n",
    "search_button=driver.find_element_by_xpath(\"//button[@class='gd-btn-mkt']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loging the website using below code\n",
    "driver.find_element_by_xpath('//button[@type=\"button\"]').click()\n",
    "time.sleep(10)\n",
    "\n",
    "driver.find_element_by_xpath('//input[@id=\"userEmail\"]').send_keys('harinathmallela7@gmail.com')\n",
    "driver.find_element_by_xpath('//input[@id=\"userPassword\"]').send_keys('glassdoor123')\n",
    "time.sleep(5)\n",
    "\n",
    "driver.find_element_by_xpath('//button[@class=\"gd-ui-button minWidthBtn css-8i7bc2\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an empty list to store details\n",
    "company_name=[]\n",
    "total_salaries=[]\n",
    "avg_salary=[]\n",
    "min_salary=[]\n",
    "max_salary=[]\n",
    "rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapping the page to get the details \n",
    "for i in driver.find_elements_by_xpath('//div[@data-test=\"job-info\"]/p[2]'):\n",
    "    company_name.append(i.text)\n",
    "for i in driver.find_elements_by_xpath('//p[@class=\"css-1uyte9r css-1kuy7z7 m-0 \"]'):\n",
    "    total_salaries.append(i.text)   \n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"col-2 d-none d-md-flex flex-row justify-content-end\"]/strong'):\n",
    "    avg_salary.append(i.text)\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"common__RangeBarStyle__values d-flex justify-content-between \"]/span[1]'):\n",
    "    min_salary.append(i.text)\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"common__RangeBarStyle__values d-flex justify-content-between \"]/span[2]'):\n",
    "    max_salary.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping each job url\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"undefined mr-sm\"]/a'):\n",
    "    urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.0', '3.9', '4.1', '3.8', '3.6', '4.0', '4.0', '3.6', '3.9', '3.6']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping the ratings using urls \n",
    "for i in urls[1:11]:\n",
    "    driver.get(i)\n",
    "    driver.find_element_by_xpath('//a[@data-label=\"Reviews\"]').click()\n",
    "    time.sleep(3)\n",
    "    Rating=driver.find_element_by_xpath(\"//div[@class='v2__EIReviewsRatingsStylesV2__ratingNum v2__EIReviewsRatingsStylesV2__large']\").text\n",
    "    rating.append(Rating)\n",
    "\n",
    "rating   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20 20 10\n"
     ]
    }
   ],
   "source": [
    "print(len(company_name),len(total_salaries),len(avg_salary),len(min_salary),len(max_salary),len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company name</th>\n",
       "      <th>Number of salaries</th>\n",
       "      <th>Average salary</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 11,46,533</td>\n",
       "      <td>₹577K</td>\n",
       "      <td>₹2,213K</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBM</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 8,97,795</td>\n",
       "      <td>₹586K</td>\n",
       "      <td>₹2,730K</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 7,38,057</td>\n",
       "      <td>₹355K</td>\n",
       "      <td>₹1,613K</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 12,39,781</td>\n",
       "      <td>₹450K</td>\n",
       "      <td>₹11,622K</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>11 salaries</td>\n",
       "      <td>₹ 13,36,142</td>\n",
       "      <td>₹1,069K</td>\n",
       "      <td>₹1,520K</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹ 8,15,192</td>\n",
       "      <td>₹502K</td>\n",
       "      <td>₹1,465K</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 11,35,221</td>\n",
       "      <td>₹202K</td>\n",
       "      <td>₹1,809K</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 11,44,243</td>\n",
       "      <td>₹575K</td>\n",
       "      <td>₹1,520K</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 14,13,288</td>\n",
       "      <td>₹1,014K</td>\n",
       "      <td>₹2,149K</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 12,07,110</td>\n",
       "      <td>₹620K</td>\n",
       "      <td>₹1,695K</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Company name Number of salaries Average salary min_salary  \\\n",
       "0               Accenture        14 salaries    ₹ 11,46,533      ₹577K   \n",
       "1                     IBM        14 salaries     ₹ 8,97,795      ₹586K   \n",
       "2      Ericsson-Worldwide        14 salaries     ₹ 7,38,057      ₹355K   \n",
       "3               Delhivery        14 salaries    ₹ 12,39,781      ₹450K   \n",
       "4      UnitedHealth Group        11 salaries    ₹ 13,36,142    ₹1,069K   \n",
       "5      Valiance Solutions         9 salaries     ₹ 8,15,192      ₹502K   \n",
       "6           ZS Associates         8 salaries    ₹ 11,35,221      ₹202K   \n",
       "7             EXL Service         8 salaries    ₹ 11,44,243      ₹575K   \n",
       "8  Optum Global Solutions         8 salaries    ₹ 14,13,288    ₹1,014K   \n",
       "9              Innovaccer         8 salaries    ₹ 12,07,110      ₹620K   \n",
       "\n",
       "  max_salary Rating  \n",
       "0    ₹2,213K    4.0  \n",
       "1    ₹2,730K    3.9  \n",
       "2    ₹1,613K    4.1  \n",
       "3   ₹11,622K    3.8  \n",
       "4    ₹1,520K    3.6  \n",
       "5    ₹1,465K    4.0  \n",
       "6    ₹1,809K    4.0  \n",
       "7    ₹1,520K    3.6  \n",
       "8    ₹2,149K    3.9  \n",
       "9    ₹1,695K    3.6  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe\n",
    "job={\"Company name\":company_name[1:11],\n",
    "     \"Number of salaries\":total_salaries[1:11],\n",
    "     \"Average salary\":avg_salary[1:11],\n",
    "     'min_salary':min_salary[1:11],\n",
    "     'max_salary':max_salary[1:11],\n",
    "    'Rating':rating}\n",
    "df=pd.DataFrame(job)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving csv file\n",
    "df.to_csv('5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. repeat this until you get data for 100 sunglasses.\n",
    "Note that all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using chromedriver and driver.get to open and load a chrome page.\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.flipkart.com/')\n",
    "driver.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the search_bar using tags and entering details to search \n",
    "driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "time.sleep(10)\n",
    "\n",
    "driver.find_element_by_xpath('//input[@title=\"Search for products, brands and more\"]').send_keys('sunglasses')\n",
    "time.sleep(10)\n",
    "driver.find_element_by_xpath('//button[@type=\"submit\"]').click()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an empty list to store details\n",
    "brand_name=[]\n",
    "description=[]\n",
    "price=[]\n",
    "discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping details\n",
    "next=0\n",
    "while next<3:\n",
    "    time.sleep(3)\n",
    "    for j in driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]'):\n",
    "        brand_name.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath('//a[contains(@class,\"IRpwTa\")]'):\n",
    "        description.append(k.text)\n",
    "    for m in driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]'):\n",
    "        price.append(m.text)\n",
    "    for n in driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]'):\n",
    "        discount.append(n.text)\n",
    "    if next==0:\n",
    "        driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "    elif next==1:\n",
    "        driver.find_element_by_xpath('//nav[@class=\"yFHi8N\"]/a[12]').click()\n",
    "    else:\n",
    "        pass\n",
    "    next+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe\n",
    "df=pd.DataFrame({})\n",
    "df['Product Brand']=brand_name[:100]\n",
    "df['Product Description']=description[:100]\n",
    "df['Price of Product']=price[:100]\n",
    "df['Discount on Product']=discount[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price of Product</th>\n",
       "      <th>Discount on Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹630</td>\n",
       "      <td>21% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹404</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹758</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹250</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection Oval Sunglasses (60)</td>\n",
       "      <td>₹764</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (49)</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>elegante</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹449</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹578</td>\n",
       "      <td>27% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Retro Square Sunglasse...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Product Brand                                Product Description  \\\n",
       "0         Fastrack   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "1   ROZZETTA CRAFT  UV Protection Retro Square Sunglasses (Free Size)   \n",
       "2   ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...   \n",
       "3         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "4           PIRASO              UV Protection Aviator Sunglasses (54)   \n",
       "..             ...                                                ...   \n",
       "95          AISLIN                 UV Protection Oval Sunglasses (60)   \n",
       "96       ROYAL SON     Polarized, UV Protection Round Sunglasses (49)   \n",
       "97        elegante      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "98        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "99  ROZZETTA CRAFT  UV Protection, Gradient Retro Square Sunglasse...   \n",
       "\n",
       "   Price of Product Discount on Product  \n",
       "0              ₹630             21% off  \n",
       "1              ₹499             77% off  \n",
       "2              ₹404             79% off  \n",
       "3              ₹758             15% off  \n",
       "4              ₹250             84% off  \n",
       "..              ...                 ...  \n",
       "95             ₹764             69% off  \n",
       "96             ₹664             66% off  \n",
       "97             ₹449             70% off  \n",
       "98             ₹578             27% off  \n",
       "99             ₹499             75% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving csv file\n",
    "df.to_csv('6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage.\n",
    "As shown in the above page you have to scrape the tick marked attributes.\n",
    "These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using chromedriver and driver.get to open and load a chrome page.\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')\n",
    "driver.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an empty list to store details\n",
    "rating=[]\n",
    "review_summary=[]\n",
    "full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exapnding the review section to get complete reviews\n",
    "driver.find_element_by_xpath('//div[@class=\"_3UAT2v _16PBlm\"]').click()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the  required details\n",
    "while (len(rating)<=100):\n",
    "    for j in driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]'):\n",
    "        rating.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]'):\n",
    "        review_summary.append(k.text)\n",
    "    for m in driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]'):\n",
    "        full_review.append(m.text)\n",
    "    \n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath(\"//span[contains(text(),'Next')]\").click()\n",
    "    time.sleep(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 110 110\n"
     ]
    }
   ],
   "source": [
    "print(len(rating),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Not recommended at all</td>\n",
       "      <td>They are selling cheep quality items. There is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>I write this review after using a week this iP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Everything is perfect pictures come out so cle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>The best all rounder iphone. Flipkart is doing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>We are on apple ecosystem for almost eight yea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating          Review_summary  \\\n",
       "0       5               Brilliant   \n",
       "1       5        Perfect product!   \n",
       "2       5           Great product   \n",
       "3       5       Worth every penny   \n",
       "4       4             Good choice   \n",
       "..    ...                     ...   \n",
       "95      5  Not recommended at all   \n",
       "96      5          Classy product   \n",
       "97      5               Fabulous!   \n",
       "98      5     Best in the market!   \n",
       "99      5          Classy product   \n",
       "\n",
       "                                          Full_review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   So far it’s been an AMAZING experience coming ...  \n",
       "..                                                ...  \n",
       "95  They are selling cheep quality items. There is...  \n",
       "96  I write this review after using a week this iP...  \n",
       "97  Everything is perfect pictures come out so cle...  \n",
       "98  The best all rounder iphone. Flipkart is doing...  \n",
       "99  We are on apple ecosystem for almost eight yea...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe\n",
    "review={\"Rating\":rating[0:100],\"Review_summary\":review_summary[0:100],\"Full_review\":full_review[0:100]}\n",
    "df=pd.DataFrame(review)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving csv file\n",
    "df.to_csv('7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "Also note that all the steps required during scraping should be done through code only and not manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using chromedriver and driver.get to open and load a chrome page.\n",
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.flipkart.com/')\n",
    "driver.implicitly_wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the search_bar using tags and entering details to search \n",
    "driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "time.sleep(10)\n",
    "\n",
    "driver.find_element_by_xpath('//div[@class=\"_3OO5Xc\"]').click()\n",
    "time.sleep(10)\n",
    "\n",
    "driver.find_element_by_xpath('//input[@title=\"Search for products, brands and more\"]').send_keys('sneakers')\n",
    "time.sleep(10)\n",
    "driver.find_element_by_xpath('//button[@type=\"submit\"]').click()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an empty list to store details\n",
    "brand_name=[]\n",
    "description=[]\n",
    "price=[]\n",
    "discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's scrape the job details using loop\n",
    "next=0\n",
    "while next<3:\n",
    "    for j in driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]'):\n",
    "        brand_name.append(j.text)\n",
    "    for k in driver.find_elements_by_xpath('//a[contains(@class,\"IRpwTa\")]'):\n",
    "        description.append(k.text)\n",
    "    for m in driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]'):\n",
    "        price.append(m.text)\n",
    "    for n in driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]'):\n",
    "        discount.append(n.text)\n",
    "    if next==0:\n",
    "        driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "    elif next==1:\n",
    "        driver.find_element_by_xpath('//nav[@class=\"yFHi8N\"]/a[12]').click()\n",
    "    else:\n",
    "        pass\n",
    "    next+=1   \n",
    "        \n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe\n",
    "df=pd.DataFrame({})\n",
    "df['Product Brand']=brand_name[:100]\n",
    "df['Product Description']=description[:100]\n",
    "df['Price of Product']=price[:100]\n",
    "df['Discount on Product']=discount[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price of Product</th>\n",
       "      <th>Discount on Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zorth</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹599</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zorth</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹599</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹474</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Svpanther</td>\n",
       "      <td>1002 Sneakers For Men</td>\n",
       "      <td>₹515</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>oxpeo</td>\n",
       "      <td>Colourblocked Trending Multicolor Ultralight c...</td>\n",
       "      <td>₹398</td>\n",
       "      <td>51% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Zorth</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹599</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹240</td>\n",
       "      <td>46% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>REEBOK CLASSICS</td>\n",
       "      <td>Reebok Clubonic Sneakers For Men</td>\n",
       "      <td>₹1,799</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Product Brand                                Product Description  \\\n",
       "0                 Zorth                                   Sneakers For Men   \n",
       "1                 Zorth                                   Sneakers For Men   \n",
       "2          Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "3               Numenzo                                   Sneakers For Men   \n",
       "4          Robbie jones                                   Sneakers For Men   \n",
       "..                  ...                                                ...   \n",
       "95            Svpanther                              1002 Sneakers For Men   \n",
       "96                oxpeo  Colourblocked Trending Multicolor Ultralight c...   \n",
       "97                Zorth                                   Sneakers For Men   \n",
       "98  World Wear Footwear                                   Sneakers For Men   \n",
       "99      REEBOK CLASSICS                   Reebok Clubonic Sneakers For Men   \n",
       "\n",
       "   Price of Product Discount on Product  \n",
       "0              ₹599             40% off  \n",
       "1              ₹599             40% off  \n",
       "2              ₹379             62% off  \n",
       "3              ₹398             60% off  \n",
       "4              ₹474             52% off  \n",
       "..              ...                 ...  \n",
       "95             ₹515             40% off  \n",
       "96             ₹398             51% off  \n",
       "97             ₹599             40% off  \n",
       "98             ₹240             46% off  \n",
       "99           ₹1,799             76% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving csv file\n",
    "df.to_csv('8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”,\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe.\n",
    "Please note that applying the filter and scraping the data , everything should be done through code only and there should not be any manual step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the drivers and URL\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()\n",
    "#Let's apply filter for price\n",
    "driver.find_element_by_xpath('//ul[@class=\"price-list\"]/li[2]').click()\n",
    "time.sleep(3)    \n",
    "#Let's apply filter for colour\n",
    "driver.find_element_by_xpath('//span[@data-colorhex=\"black\"]').click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an empty list to store details\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the webpage using below code\n",
    "next=0\n",
    "while next<3:\n",
    "    for q in driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]'):\n",
    "        brand.append(q.text)\n",
    "        \n",
    "    for q in driver.find_elements_by_xpath('//h4[@class=\"product-product\"]'):\n",
    "        description.append(q.text)\n",
    "        \n",
    "    for q in driver.find_elements_by_xpath('//div[@class=\"product-price\"]'):\n",
    "        price.append(q.text)\n",
    "    if next==0:\n",
    "        driver.find_element_by_xpath('//li[@class=\"pagination-next\"]').click()\n",
    "    elif next==1:\n",
    "        driver.find_element_by_xpath('//li[@class=\"pagination-next\"]').click()\n",
    "    else:\n",
    "        pass\n",
    "    next+=1 \n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 150 150\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(description),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Sneakers</td>\n",
       "      <td>Rs. 10995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Nite Jogger Fluid Sneakers</td>\n",
       "      <td>Rs. 8449Rs. 12999(35% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Men Wingtip Oxford Sneakers</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Men ZEROGRAND GLOBAL SLIP ON</td>\n",
       "      <td>Rs. 14999Rs. 19999(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Men GENERATION ZEROGRAND STITCHLITE</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex RS-Fast Sneakers</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Leather Solid Loafers</td>\n",
       "      <td>Rs. 14999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Charged Intake 4 Running Shoes</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men X9000L3 Heat.RDY Running</td>\n",
       "      <td>Rs. 9599Rs. 11999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men Supernova Running Shoes</td>\n",
       "      <td>Rs. 7999Rs. 9999(20% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                          Description  \\\n",
       "0               Nike            Men JORDAN DELTA Sneakers   \n",
       "1   ADIDAS Originals       Men Nite Jogger Fluid Sneakers   \n",
       "2          Cole Haan          Men Wingtip Oxford Sneakers   \n",
       "3          Cole Haan         Men ZEROGRAND GLOBAL SLIP ON   \n",
       "4          Cole Haan  Men GENERATION ZEROGRAND STITCHLITE   \n",
       "..               ...                                  ...   \n",
       "95              Puma              Unisex RS-Fast Sneakers   \n",
       "96              ALDO                Leather Solid Loafers   \n",
       "97      UNDER ARMOUR       Charged Intake 4 Running Shoes   \n",
       "98            ADIDAS         Men X9000L3 Heat.RDY Running   \n",
       "99            ADIDAS          Men Supernova Running Shoes   \n",
       "\n",
       "                          Price  \n",
       "0                     Rs. 10995  \n",
       "1    Rs. 8449Rs. 12999(35% OFF)  \n",
       "2                     Rs. 12999  \n",
       "3   Rs. 14999Rs. 19999(25% OFF)  \n",
       "4                     Rs. 11999  \n",
       "..                          ...  \n",
       "95                     Rs. 9999  \n",
       "96                    Rs. 14999  \n",
       "97                     Rs. 9999  \n",
       "98   Rs. 9599Rs. 11999(20% OFF)  \n",
       "99    Rs. 7999Rs. 9999(20% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the DataFrame using pandas\n",
    "job={\"Brand\":brand[:100],\n",
    "     \"Description\":description[:100],\n",
    "     \"Price\":price[:100]}\n",
    "df=pd.DataFrame(job)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the price column data only to get the price figure. \n",
    "new_price=df['Price'].str.split(\"Rs.\",n=2,expand=True)\n",
    "df['Price in Rs']=new_price[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping price coloumn \n",
    "df.drop(columns=('Price'),axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price in Rs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Sneakers</td>\n",
       "      <td>10995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Nite Jogger Fluid Sneakers</td>\n",
       "      <td>8449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Men Wingtip Oxford Sneakers</td>\n",
       "      <td>12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Men ZEROGRAND GLOBAL SLIP ON</td>\n",
       "      <td>14999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Men GENERATION ZEROGRAND STITCHLITE</td>\n",
       "      <td>11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex RS-Fast Sneakers</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Leather Solid Loafers</td>\n",
       "      <td>14999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Charged Intake 4 Running Shoes</td>\n",
       "      <td>9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men X9000L3 Heat.RDY Running</td>\n",
       "      <td>9599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men Supernova Running Shoes</td>\n",
       "      <td>7999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                          Description Price in Rs\n",
       "0               Nike            Men JORDAN DELTA Sneakers       10995\n",
       "1   ADIDAS Originals       Men Nite Jogger Fluid Sneakers        8449\n",
       "2          Cole Haan          Men Wingtip Oxford Sneakers       12999\n",
       "3          Cole Haan         Men ZEROGRAND GLOBAL SLIP ON       14999\n",
       "4          Cole Haan  Men GENERATION ZEROGRAND STITCHLITE       11999\n",
       "..               ...                                  ...         ...\n",
       "95              Puma              Unisex RS-Fast Sneakers        9999\n",
       "96              ALDO                Leather Solid Loafers       14999\n",
       "97      UNDER ARMOUR       Charged Intake 4 Running Shoes        9999\n",
       "98            ADIDAS         Men X9000L3 Heat.RDY Running        9599\n",
       "99            ADIDAS          Men Supernova Running Shoes        7999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving csv file\n",
    "df.to_csv('9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q10: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”.\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop.\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using below code to open and load the chrome page\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching for laptop product and then clicking search button\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "driver.find_element_by_xpath('//input[@id=\"twotabsearchtextbox\"]').send_keys('Laptop')\n",
    "driver.find_element_by_xpath('//input[@type=\"submit\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying  filter for \"Intel Core i7\"\n",
    "driver.find_element_by_xpath('//li[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a').click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty lists\n",
    "Title=[]\n",
    "rating=[]\n",
    "Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the list of url of laptops\n",
    "URL=[]\n",
    "\n",
    "laptop=driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
    "for i in laptop:\n",
    "    laptop2=i.find_element_by_tag_name(\"a\")\n",
    "    URL.append(laptop2.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the length of url's\n",
    "len(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the details\n",
    "for i in URL[0:10]:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        title=driver.find_element_by_xpath('//*[@id=\"productTitle\"]').text\n",
    "        Title.append(title)\n",
    "    except NoSuchElementException:\n",
    "        Title.append('Null')\n",
    "        \n",
    "    try:\n",
    "        price=driver.find_element_by_xpath('//td[@class=\"a-span12\"]/span').text\n",
    "        Price.append(price)\n",
    "    except NoSuchElementException:\n",
    "        price1='NA'\n",
    "        Price.append(price1)\n",
    "    try:\n",
    "        rat=driver.find_element_by_xpath('//span[@class=\"a-size-medium a-color-base\"]').text\n",
    "        rating.append(rat)\n",
    "    except:\n",
    "        rating.append('na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the selected filter of i7 laptop\n",
    "driver.find_element_by_xpath('//input[@type=\"submit\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying filter for \"Intel Core i9\"\n",
    "driver.find_element_by_xpath('//li[@id=\"p_n_feature_thirteen_browse-bin/16757432031\"]/span/a').click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the list of url of laptops\n",
    "URL=[]\n",
    "\n",
    "laptop=driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
    "for i in laptop:\n",
    "    laptop2=i.find_element_by_tag_name(\"a\")\n",
    "    URL.append(laptop2.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the details\n",
    "for i in URL[0:10]:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        title=driver.find_element_by_xpath('//*[@id=\"productTitle\"]').text\n",
    "        Title.append(title)\n",
    "    except NoSuchElementException:\n",
    "        Title.append('Null')\n",
    "        \n",
    "    try:\n",
    "        price=driver.find_element_by_xpath('//td[@class=\"a-span12\"]/span').text\n",
    "        Price.append(price)\n",
    "    except NoSuchElementException:\n",
    "        price1='NA'\n",
    "        Price.append(price1)\n",
    "    try:\n",
    "        rat=driver.find_element_by_xpath('//span[@class=\"a-size-medium a-color-base\"]').text\n",
    "        rating.append(rat)\n",
    "    except:\n",
    "        rating.append('na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dell G3 3500 Gaming 15.6inch ( 39.62 cms) 120h...</td>\n",
       "      <td>₹ 82,490.00</td>\n",
       "      <td>3.9 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo Yoga Slim 7 10th Gen Intel Core i7 14 i...</td>\n",
       "      <td>₹ 83,990.00</td>\n",
       "      <td>3.2 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>₹ 53,999.00</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo Yoga Slim 7i 11th Gen Intel Core i7 14\"...</td>\n",
       "      <td>₹ 97,990.00</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...</td>\n",
       "      <td>₹ 3,43,099.00</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...</td>\n",
       "      <td>₹ 1,35,490.00</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>₹ 29,990.00</td>\n",
       "      <td>3.1 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>₹ 24,990.00</td>\n",
       "      <td>2.6 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acer Nitro 5 Intel Core i7-9th Gen 17.3-inch D...</td>\n",
       "      <td>₹ 69,990.00</td>\n",
       "      <td>3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) Lenovo Intel 4th Gen Core i7-4980HQ ...</td>\n",
       "      <td>₹ 46,290.00</td>\n",
       "      <td>3 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...</td>\n",
       "      <td>₹ 2,99,325.00</td>\n",
       "      <td>3.8 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 1...</td>\n",
       "      <td>₹ 4,13,890.00</td>\n",
       "      <td>3.7 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ASUS ZenBook Pro Duo UX581 Intel Core i9 9th G...</td>\n",
       "      <td>₹ 2,79,990.00</td>\n",
       "      <td>3.8 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dell XPS 9570 15.6\" (39.62cms) UHD Laptop (8th...</td>\n",
       "      <td>₹ 2,49,990.00</td>\n",
       "      <td>2.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...</td>\n",
       "      <td>₹ 2,62,990.00</td>\n",
       "      <td>3.7 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ASUS ROG Zephyrus Duo 15, 15.6\" FHD 300Hz/3ms,...</td>\n",
       "      <td>₹ 2,66,990.00</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ASUS ROG Strix Scar 17 (2020), 17.3\" FHD 300Hz...</td>\n",
       "      <td>₹ 2,77,639.00</td>\n",
       "      <td>4.8 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(Renewed) Dell XPS 9570 Laptop|i9-8950HK|32GB ...</td>\n",
       "      <td>₹ 1,89,900.00</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dell G7 7500 15.6inch FHD 300 Hz Display Gamin...</td>\n",
       "      <td>₹ 2,00,690.00</td>\n",
       "      <td>3.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HP Omen X 2S Core i9 9th Gen 15.6-inch Dual Sc...</td>\n",
       "      <td>₹ 3,45,800.00</td>\n",
       "      <td>4.5 out of 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title          Price  \\\n",
       "0   Dell G3 3500 Gaming 15.6inch ( 39.62 cms) 120h...    ₹ 82,490.00   \n",
       "1   Lenovo Yoga Slim 7 10th Gen Intel Core i7 14 i...    ₹ 83,990.00   \n",
       "2   Mi Notebook Horizon Edition 14 Intel Core i5-1...    ₹ 53,999.00   \n",
       "3   Lenovo Yoga Slim 7i 11th Gen Intel Core i7 14\"...    ₹ 97,990.00   \n",
       "4   Asus ROG Zephyrus S Ultra Slim Gaming Laptop, ...  ₹ 3,43,099.00   \n",
       "5   Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...  ₹ 1,35,490.00   \n",
       "6   Life Digital Laptop 15.6-inch (39.62 cms) (Int...    ₹ 29,990.00   \n",
       "7   Life Digital Laptop 15.6-inch (39.62 cms) (Int...    ₹ 24,990.00   \n",
       "8   Acer Nitro 5 Intel Core i7-9th Gen 17.3-inch D...    ₹ 69,990.00   \n",
       "9   (Renewed) Lenovo Intel 4th Gen Core i7-4980HQ ...    ₹ 46,290.00   \n",
       "10  ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...  ₹ 2,99,325.00   \n",
       "11  ASUS ROG G703GI-E5148T 17.3\" (43.94 cms) FHD 1...  ₹ 4,13,890.00   \n",
       "12  ASUS ZenBook Pro Duo UX581 Intel Core i9 9th G...  ₹ 2,79,990.00   \n",
       "13  Dell XPS 9570 15.6\" (39.62cms) UHD Laptop (8th...  ₹ 2,49,990.00   \n",
       "14  Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...  ₹ 2,62,990.00   \n",
       "15  ASUS ROG Zephyrus Duo 15, 15.6\" FHD 300Hz/3ms,...  ₹ 2,66,990.00   \n",
       "16  ASUS ROG Strix Scar 17 (2020), 17.3\" FHD 300Hz...  ₹ 2,77,639.00   \n",
       "17  (Renewed) Dell XPS 9570 Laptop|i9-8950HK|32GB ...  ₹ 1,89,900.00   \n",
       "18  Dell G7 7500 15.6inch FHD 300 Hz Display Gamin...  ₹ 2,00,690.00   \n",
       "19  HP Omen X 2S Core i9 9th Gen 15.6-inch Dual Sc...  ₹ 3,45,800.00   \n",
       "\n",
       "          rating  \n",
       "0   3.9 out of 5  \n",
       "1   3.2 out of 5  \n",
       "2   4.4 out of 5  \n",
       "3             na  \n",
       "4   4.2 out of 5  \n",
       "5   4.3 out of 5  \n",
       "6   3.1 out of 5  \n",
       "7   2.6 out of 5  \n",
       "8     3 out of 5  \n",
       "9     3 out of 5  \n",
       "10  3.8 out of 5  \n",
       "11  3.7 out of 5  \n",
       "12  3.8 out of 5  \n",
       "13  2.4 out of 5  \n",
       "14  3.7 out of 5  \n",
       "15            na  \n",
       "16  4.8 out of 5  \n",
       "17            na  \n",
       "18  3.4 out of 5  \n",
       "19  4.5 out of 5  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the DataFrame using pandas\n",
    "product={\"Title\":Title,\n",
    "     \"Price\":Price,\n",
    "     \"rating\":rating}\n",
    "df=pd.DataFrame(product)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving csv file\n",
    "df.to_csv('10.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
